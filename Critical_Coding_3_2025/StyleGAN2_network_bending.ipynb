{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasper-zheng/teaching/blob/main/Critical_Coding_3_2025/StyleGAN2_network_bending.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d736cdb1",
      "metadata": {
        "id": "d736cdb1"
      },
      "source": [
        "# Network Bending an Image Generation Model  \n",
        "\n",
        "###### A tutorial on [Network Bending](https://arxiv.org/abs/2005.12420) (Broad et al., 2021) by [Jasper Shuoyang Zheng](https://jasperzheng.cc/).  \n",
        "\n",
        "[Network Bending](https://terencebroad.com/research/network-bending) is the art of intervening in the computational graph of a deep learning model during inference. Some examples of network bending to help spur your imagination:\n",
        "\n",
        " - Corrupting the weights of a trained model, as in [Mario Klingemann](https://underdestruction.com/2018/12/29/memories-of-passersby-i/) and [Blazej Kotowski](https://www.upf.edu/web/mdm-dtic/blog/-/blogs/network-bending-conducting-operations-on-the-open-bodies-of-neural-nets-by-blazej-kotowski);\n",
        " - Adding transformation layers in the model to manipulate the internal representations, as in [Terence Broad](https://terencebroad.com/works/teratome);  \n",
        " - Disrupting the way how data is distributed in the latent space, as in [Jasper Zheng](https://jasper-zheng.github.io/nn_terrain/);\n",
        " - ... anything else you can imagine!\n",
        "\n",
        "In this notebook, we'll hack into the inference process of a pre-trained [StyleGAN2](https://github.com/NVlabs/stylegan3) model by applying some arbitrary transformations to the activation maps.  \n",
        "\n",
        "**Please make sure that you have selected a runtime with a GPU!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-gYiYQ2oF-Qn",
      "metadata": {
        "id": "-gYiYQ2oF-Qn"
      },
      "source": [
        "We'll use a pre-trained StyleGAN3 model, the model can be downloaded using the command below:  \n",
        "(Alternatively, if the command doesn't work, just navigate to the url and download it, place it next to this notebook)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installation (only run this once)\n",
        "\n",
        "# clone the official stylegan repository\n",
        "!git clone https://github.com/NVlabs/stylegan3.git\n",
        "!pip install ninja\n",
        "!pip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu128"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "LwePBr-35nlk"
      },
      "id": "LwePBr-35nlk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64da36a7-34b9-4d31-bf7e-06de49e70f9a",
      "metadata": {
        "cellView": "form",
        "id": "64da36a7-34b9-4d31-bf7e-06de49e70f9a",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#@title 01 - Download model, import librarys\n",
        "\n",
        "import sys\n",
        "\n",
        "base_dir = 'stylegan3'\n",
        "sys.path.append(f'{base_dir}')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from torchvision.transforms.functional import to_pil_image, affine\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "BILINEAR = InterpolationMode.BILINEAR\n",
        "NEAREST = InterpolationMode.NEAREST\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import dnnlib\n",
        "import legacy\n",
        "\n",
        "source_model_type = 'ffhq' #@param['ffhq', 'metface', 'cat']\n",
        "\n",
        "source_model_download_path = {\"ffhq\":   \"https://api.ngc.nvidia.com/v2/models/org/nvidia/team/research/stylegan2/1/files?redirect=true\\&path=stylegan2-ffhq-1024x1024.pkl\",\n",
        "                              \"metface\":    \"https://api.ngc.nvidia.com/v2/models/org/nvidia/team/research/stylegan2/1/files?redirect=true\\&path=stylegan2-metfaces-1024x1024.pkl\",\n",
        "                              \"cat\":    \"https://api.ngc.nvidia.com/v2/models/org/nvidia/team/research/stylegan2/1/files?redirect=true\\&path=stylegan2-afhqcat-512x512.pkl\"}\n",
        "\n",
        "model_names = {\"ffhq\":   \"stylegan2-ffhq-1024x1024.pkl\",\n",
        "               \"metface\":    \"stylegan2-metfaces-1024x1024.pkl\",\n",
        "               \"cat\":    \"stylegan2-afhqcat-512x512.pkl\"}\n",
        "\n",
        "model_url = source_model_download_path[source_model_type]\n",
        "file_name = model_names[source_model_type]\n",
        "\n",
        "\n",
        "\n",
        "!curl -L 'https://api.ngc.nvidia.com/v2/models/org/nvidia/team/research/stylegan2/1/files?redirect=true&path=stylegan2-ffhq-1024x1024.pkl' -o {file_name}\n",
        "# !wget --content-disposition {model_url} -O {file_name}\n",
        "\n",
        "\n",
        "def slerp(val, low, high):\n",
        "    '''\n",
        "    original: Animating Rotation with Quaternion Curves, Ken Shoemake\n",
        "    Code: https://github.com/soumith/dcgan.torch/issues/14, Tom White\n",
        "    '''\n",
        "    if len(low.shape) == 1:\n",
        "        omega = np.arccos(np.dot(low/np.linalg.norm(low), high/np.linalg.norm(high)))\n",
        "        so = np.sin(omega)\n",
        "        return np.sin((1.0-val)*omega) / so * low + np.sin(val*omega)/so * high\n",
        "    elif len(low.shape) == 2:\n",
        "        ws = []\n",
        "        for i in range(low.shape[0]):\n",
        "            omega = np.arccos(np.dot(low[i,:]/np.linalg.norm(low[i,:]), high[i,:]/np.linalg.norm(high[i,:])))\n",
        "            so = np.sin(omega)\n",
        "            w = np.sin((1.0-val)*omega) / so * low[i,:] + np.sin(val*omega)/so * high[i,:]\n",
        "            ws.append(w)\n",
        "        return torch.tensor(np.array(ws))\n",
        "\n",
        "def slerp_interpolation(z1, z2, num_interp):\n",
        "    # create intervals\n",
        "    interp_vals = np.linspace(1./num_interp, 1, num=num_interp)\n",
        "\n",
        "    # Convert latent vectors to numpy arrays\n",
        "    latent_a_np = z1.cpu().numpy().squeeze()\n",
        "    latent_b_np = z2.cpu().numpy().squeeze()\n",
        "\n",
        "    # Create our spherical interpolation between two points\n",
        "    latent_interp = torch.tensor(np.array([slerp(v, latent_a_np, latent_b_np) for v in interp_vals], dtype=np.float32))\n",
        "    return latent_interp\n",
        "\n",
        "def batch_norm(x, min=None, max=None):\n",
        "    min = x.min() if min is None else min\n",
        "    max = x.max() if max is None else max\n",
        "    return (x - min) / (max - min)\n",
        "\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "\n",
        "print(torch.__version__)\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f3b16c",
      "metadata": {
        "id": "75f3b16c"
      },
      "source": [
        "## 2 - Load a pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6563ff6e-4e47-4654-92bc-b5a761c8315e",
      "metadata": {
        "id": "6563ff6e-4e47-4654-92bc-b5a761c8315e"
      },
      "outputs": [],
      "source": [
        "network_pkl = file_name\n",
        "\n",
        "with dnnlib.util.open_url(network_pkl) as f:\n",
        "    G = legacy.load_network_pkl(f)['G_ema'].to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7474a45e",
      "metadata": {
        "id": "7474a45e"
      },
      "source": [
        "## 3 - Do a forward pass to generate an image  \n",
        "\n",
        "Before doing any network bending, let's have a look at how generater in StyleGAN works.  \n",
        "The generater takes a latent vector $z$ and generates an image corresponding to $z$.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95082ea2",
      "metadata": {
        "id": "95082ea2"
      },
      "outputs": [],
      "source": [
        "truncation_psi = 0.6  # truncation trick allows faces to converge to the “mean” face, if truncation_psi == 0 then you'll always get the “mean” face\n",
        "c = None   # class labels (not used in this example)\n",
        "torch.manual_seed(422)\n",
        "\n",
        "# Generate a random latent vector:\n",
        "z = torch.randn([1, G.z_dim]).to(device)  # create a (1, 512) shape tensor with random numbers, sampled from a standard normal distribution\n",
        "print(f'Vector shape: {z.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df3cebf",
      "metadata": {
        "id": "2df3cebf"
      },
      "source": [
        "Now we can do a regular forward pass and plot the output image  \n",
        "(if you're on colab running this for the first time, it can take a while... roughly 1~2mins)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7efae8cd",
      "metadata": {
        "id": "7efae8cd"
      },
      "outputs": [],
      "source": [
        "img = G(z, c, truncation_psi=truncation_psi)\n",
        "\n",
        "print(f'Output shape: {img.shape}')\n",
        "\n",
        "img = batch_norm(img)\n",
        "plt.imshow(to_pil_image(img[0].cpu()))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "642b3276",
      "metadata": {
        "id": "642b3276"
      },
      "source": [
        "## 4 - Customised forward pass & Visualising activation maps  \n",
        "\n",
        "Calling the generator `G()` will use the default `forward()` function in PyTorch (see: [PyTorch Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)).   \n",
        "Instead of using the default one, we can also use write our customised forward pass function, so that we can intervene in the model's inference process.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f68f080",
      "metadata": {
        "id": "5f68f080"
      },
      "source": [
        "However, first we need to know some basics about how the generator in StyleGAN works:  \n",
        "\n",
        "1. First, our latent vector $z$ is processed by a mapping network, the output is an intermediate style vector $w$, which is a list of 512 dimension vector.\n",
        "2. Then $w$ is processed by the most important bit is the **synthesis network**: a 8-block convolutional neural network.  \n",
        "3. The synthesis network starts by a $4\\times 4$ noise, each layer scale up the size by 2, so in the end we get a $1024\\times 1024$ output.  \n",
        "\n",
        "Later our \"network bending\" will operate on the **synthesis network**.\n",
        "\n",
        "![net.jpg](data:image/jpeg;base64,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)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93738c4c",
      "metadata": {
        "id": "93738c4c"
      },
      "outputs": [],
      "source": [
        "# Check the model's synthesis blocks\n",
        "G.synthesis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a93e0682",
      "metadata": {
        "id": "a93e0682"
      },
      "source": [
        "In our customised forward pass, we can add a `activation_maps` list to keep track of all the internal activation maps.  \n",
        "We can also print the size of all intermediate tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f5eda07",
      "metadata": {
        "id": "6f5eda07"
      },
      "outputs": [],
      "source": [
        "def customised_forward_pass(z, truncation_psi, verbose=False):\n",
        "    # run the mapping network to get the intermediate style vector w\n",
        "    w = G.mapping(z, None, truncation_psi=truncation_psi).to(torch.float32)\n",
        "    block_w = []\n",
        "\n",
        "    # these are some process we need to do to the w... not important\n",
        "    w_idx = 0\n",
        "    for res in G.synthesis.block_resolutions:\n",
        "        block = getattr(G.synthesis, f'b{res}')\n",
        "        block_w.append(w.narrow(1, w_idx, block.num_conv + block.num_torgb))\n",
        "        w_idx += block.num_conv\n",
        "\n",
        "    x = img = None\n",
        "    activation_maps = []\n",
        "    # now we run the synthesis network to get the final image output\n",
        "    # \"res\" means resolution\n",
        "    for res, current_w in zip(G.synthesis.block_resolutions, block_w):\n",
        "        # this is to get the specific block in the synthesis network\n",
        "        block = getattr(G.synthesis, f'b{res}')\n",
        "\n",
        "        # run the block,\n",
        "        x, img = block(x, img, current_w)\n",
        "\n",
        "        # we keep track of the activation maps\n",
        "        activation_maps.append(x)\n",
        "\n",
        "        # print the shape, min and max of the activation map\n",
        "        if verbose:\n",
        "            print(f\"activation map b{res}: {x.shape} min: {x.min():.4f} max: {x.max():.4f}\")\n",
        "\n",
        "    return img, activation_maps"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfaea112",
      "metadata": {
        "id": "dfaea112"
      },
      "source": [
        "Let's use our customised forward pass function to generate an image.  \n",
        "And since we have all activation maps retrieved, we can plot and see how they look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4153b341",
      "metadata": {
        "id": "4153b341"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(422)\n",
        "z = torch.randn([1, G.z_dim]).to(device)\n",
        "\n",
        "# note that you can use the \"verbose\" argument to stop printing the shapes if you don't want to see them\n",
        "img, activation_maps = customised_forward_pass(z, truncation_psi, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e67ff0",
      "metadata": {
        "id": "86e67ff0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "for i in range(len(activation_maps)):\n",
        "    plt.subplot(len(activation_maps),1,i+1)\n",
        "    plt.axis('off')\n",
        "    map_this_block = batch_norm(activation_maps[i].permute(1,0,2,3),min=-2, max=4)\n",
        "    grid = to_pil_image(make_grid(map_this_block[:20], nrow = 10).cpu().clamp(0,1))\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "img = batch_norm(img)\n",
        "plt.imshow(to_pil_image(img[0].cpu()))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Meeting Point 1**  \n",
        "\n",
        "Before we proceed to the network bending activity, let's pause here and get back to the lecture, we'll talk a bit about transformation layers that can be applied for network bending.\n",
        "\n",
        "**While you're waiting for others to finish, here are some tasks you can do:**  \n",
        " - Change the number in the line `torch.manual_seed(422)`, and re-run the `customised_forward_pass` step to experiment with other random seed;\n",
        " - Or, manually adjust some numbers in the `z` variable (the latent vector), and see if you can get some different generation results.\n"
      ],
      "metadata": {
        "id": "2_NiZbqE8pBy"
      },
      "id": "2_NiZbqE8pBy"
    },
    {
      "cell_type": "markdown",
      "id": "4cc1f12c",
      "metadata": {
        "id": "4cc1f12c"
      },
      "source": [
        "## 5 - Network Bending!  \n",
        "\n",
        "Now it's time to bend our model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4406ea7b",
      "metadata": {
        "id": "4406ea7b"
      },
      "source": [
        "### 5.1 - Bending the forward pass\n",
        "\n",
        "Having our customised forward pass means we have full control over the model's inference process.\n",
        "\n",
        "We can slightly revise our forward pass function, but this time, we can leave some backdoors for inserting transformations in between the network's synthesis blocks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6feb4aa",
      "metadata": {
        "id": "b6feb4aa"
      },
      "outputs": [],
      "source": [
        "def bending_forward_pass(z, truncation_psi, transformations=None, verbose=False):\n",
        "    # run the mapping network to get the intermediate style vector w\n",
        "    w = G.mapping(z, None, truncation_psi=truncation_psi).to(torch.float32)\n",
        "    block_w = []\n",
        "\n",
        "    # these are some process we need to do to the w... not important\n",
        "    w_idx = 0\n",
        "    for res in G.synthesis.block_resolutions:\n",
        "        block = getattr(G.synthesis, f'b{res}')\n",
        "        block_w.append(w.narrow(1, w_idx, block.num_conv + block.num_torgb))\n",
        "        w_idx += block.num_conv\n",
        "\n",
        "    x = img = None\n",
        "    activation_maps = []\n",
        "    # now we run the synthesis network to get the final image output\n",
        "    for res, current_w in zip(G.synthesis.block_resolutions, block_w):\n",
        "        # this is to get the specific block in the synthesis network\n",
        "        block = getattr(G.synthesis, f'b{res}')\n",
        "\n",
        "        # run the block,\n",
        "        x, img = block(x, img, current_w)\n",
        "\n",
        "        # we keep track of the activation maps\n",
        "        activation_maps.append(x)\n",
        "\n",
        "        # print the shape, min and max of the activation map\n",
        "        if verbose:\n",
        "            print(f\"activation map b{res}: {x.shape} min: {x.min():.4f} max: {x.max():.4f}\")\n",
        "\n",
        "\n",
        "        # Right after each synthesis block,\n",
        "        # we'll add the backdoors for network bending here:\n",
        "        # --------------------- BENDING ---------------------\n",
        "\n",
        "        # apply the transformations to the activation map:\n",
        "\n",
        "        # first, check if we do have the transformations template\n",
        "        if transformations is None:\n",
        "            continue # continue means skip the following codes in this for-loop\n",
        "\n",
        "        # then, check if we have the transformations for this block\n",
        "        if transformations.get(f'b{res}') is None:\n",
        "            continue\n",
        "\n",
        "        # we'll skip the block if there are no transformations\n",
        "        if len(transformations[f'b{res}']) == 0:\n",
        "            continue\n",
        "\n",
        "        # if we made it here, we apply all transformations in this block\n",
        "        for tf in transformations[f'b{res}']:\n",
        "            torch.manual_seed(42)\n",
        "            x = tf(x)\n",
        "\n",
        "        activation_maps.append(x)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"bent b{res}: {x.shape} min: {x.min():.4f} max: {x.max():.4f}\")\n",
        "\n",
        "        # ------------------- BENDING END -------------------\n",
        "\n",
        "    return img, activation_maps"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa61c64f",
      "metadata": {
        "id": "fa61c64f"
      },
      "source": [
        "### 5.2 - Transformation template  \n",
        "\n",
        "We can insert transformations as Python lambda functions.  \n",
        "Lambda functions are one-line anonymous functions that can be passed as arguments. More explanations [here](https://www.w3schools.com/python/python_lambda.asp)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f014c58f",
      "metadata": {
        "id": "f014c58f"
      },
      "source": [
        "\n",
        "Here is a list of PyTorch transformations we can use as materials:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e98e90d3",
      "metadata": {
        "id": "e98e90d3"
      },
      "outputs": [],
      "source": [
        "# Basic arithmetic:\n",
        "# Add\n",
        "lambda x: x.add(1)\n",
        "# Multiply\n",
        "lambda x: x.mul(2)\n",
        "\n",
        "# Affine transformations (rotate, XY-translate, scale, shear):\n",
        "# documentation: https://pytorch.org/vision/main/generated/torchvision.transforms.functional.affine.html\n",
        "lambda x: affine(x, angle=90, translate=[0,0], scale=1, shear=0, interpolation=BILINEAR)\n",
        "\n",
        "# Noise\n",
        "# documentation: https://pytorch.org/docs/stable/generated/torch.rand_like.html\n",
        "lambda x: x + torch.randn_like(x) * 1.0\n",
        "\n",
        "# Blur via average-pool\n",
        "# documentation: https://pytorch.org/docs/stable/generated/torch.nn.functional.avg_pool2d.html\n",
        "# Be careful with the `kernel_size` and `padding` to keep output the same size as input\n",
        "lambda x: torch.nn.functional.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "# Binary-threshold\n",
        "# documentation: https://pytorch.org/docs/main/generated/torch.where.html\n",
        "lambda x: torch.where(x>0, -1.0, 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7fc3223",
      "metadata": {
        "id": "b7fc3223"
      },
      "source": [
        "The following is a template for transformations,  \n",
        "Please **add/ change/ remove the codes** below, to create your own network bending template:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb13ba6",
      "metadata": {
        "id": "ceb13ba6"
      },
      "outputs": [],
      "source": [
        "transformations = {\n",
        "    \"b4\": [\n",
        "        # lambda x: # do something here:\n",
        "        lambda x: x.mul(1.2).add(-0.8),\n",
        "    ],\n",
        "    \"b8\": [\n",
        "        # lambda x: # do something here:\n",
        "        lambda x: affine(x, angle=0, translate=[0,1], scale=1, shear=0, interpolation=BILINEAR),\n",
        "        lambda x: torch.where(x>0, x, 1.0),\n",
        "    ],\n",
        "    \"b16\": [\n",
        "        # lambda x: # do something here:\n",
        "        lambda x: x + torch.randn_like(x) * 0.8\n",
        "    ],\n",
        "    \"b32\": [\n",
        "        # lambda x: # do something here:\n",
        "        lambda x: affine(x, angle=0, translate=[0,-4], scale=1, shear=0, interpolation=BILINEAR, fill=1.0),\n",
        "    ],\n",
        "    \"b64\": [\n",
        "        # lambda x: # do something here:\n",
        "    ],\n",
        "    \"b128\": [\n",
        "        # lambda x: # do something here:\n",
        "    ],\n",
        "    \"b256\": [\n",
        "        # lambda x: # do something here:\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e49f274e",
      "metadata": {
        "id": "e49f274e"
      },
      "source": [
        "### 5.3 - Test our corrupted network  \n",
        "\n",
        "Now our network is bent! Do a forward pass to see the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bbd0f37",
      "metadata": {
        "id": "3bbd0f37"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(422)\n",
        "z = torch.randn([1, G.z_dim]).to(device)\n",
        "\n",
        "# note that you can use the \"verbose\" argument to stop printing the shapes if you don't want to see them\n",
        "img, activation_maps = bending_forward_pass(z, truncation_psi, transformations=transformations, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c0199f",
      "metadata": {
        "id": "21c0199f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "for i in range(len(activation_maps)):\n",
        "    plt.subplot(len(activation_maps),1,i+1)\n",
        "    plt.axis('off')\n",
        "    map_this_block = batch_norm(activation_maps[i].permute(1,0,2,3),min=-2, max=4)\n",
        "    grid = to_pil_image(make_grid(map_this_block[:20], nrow = 10).cpu().clamp(0,1))\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "img = batch_norm(img)\n",
        "plt.imshow(to_pil_image(img[0].cpu()))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78b6c65",
      "metadata": {
        "id": "c78b6c65"
      },
      "source": [
        "Use this command to display the result in full-resolution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ced14240",
      "metadata": {
        "id": "ced14240"
      },
      "outputs": [],
      "source": [
        "display(to_pil_image(img[0].cpu()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea288cb4",
      "metadata": {
        "id": "ea288cb4"
      },
      "source": [
        "## 6 - [Optional] Make a video\n",
        "\n",
        "We can create an animated latent space interpolation with corrupted network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69942a36",
      "metadata": {
        "id": "69942a36"
      },
      "source": [
        "### 6.1 - Latent space interpolation\n",
        "\n",
        "We will create two random latent vectors as starting and ending point. We can interpolate between them using a slerp function, this will create a spherical interpolation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "798f89fa",
      "metadata": {
        "id": "798f89fa"
      },
      "outputs": [],
      "source": [
        "# from utils import slerp_interpolation\n",
        "from base64 import b64encode\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27e908de",
      "metadata": {
        "id": "27e908de"
      },
      "outputs": [],
      "source": [
        "# define how many vectors we want\n",
        "num_interp = 100\n",
        "\n",
        "torch.manual_seed(422)\n",
        "z1 = torch.randn([1, G.z_dim]).to(device)\n",
        "\n",
        "torch.manual_seed(423)\n",
        "z2 = torch.randn([1, G.z_dim]).to(device)\n",
        "\n",
        "latent_interp = slerp_interpolation(z1, z2, num_interp)\n",
        "\n",
        "latent_interp.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc0f2300",
      "metadata": {
        "id": "bc0f2300"
      },
      "source": [
        "Now we have 100 latent vectors, each vector has 512 dimensions (512 is the dimensionality of the latent vector).  \n",
        "Next, we'll create a folder to store all generated frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6853e052",
      "metadata": {
        "id": "6853e052"
      },
      "outputs": [],
      "source": [
        "folder_name = 'animated_network_bending'\n",
        "\n",
        "# create a directory to save the images\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d18602a",
      "metadata": {
        "id": "5d18602a"
      },
      "source": [
        "Then we're going to loop through all latent vectors and forward pass each of them to our corrupted network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ba3f1b3",
      "metadata": {
        "id": "6ba3f1b3"
      },
      "outputs": [],
      "source": [
        "# For each latent vector in our interpolation\n",
        "for i,latent in enumerate(latent_interp):\n",
        "    # Convert to torch tensor\n",
        "    latent = latent.unsqueeze(0).to(device)\n",
        "    # Generate image using bent network\n",
        "    img, _ = bending_forward_pass(latent, truncation_psi, transformations=transformations, verbose=False)\n",
        "    # Convert to an image and save\n",
        "    img = batch_norm(img)\n",
        "    image = to_pil_image(img[0].cpu())\n",
        "    image.save(f'./{folder_name}/{i:05}.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca429ba3",
      "metadata": {
        "id": "ca429ba3"
      },
      "source": [
        "Now we should have all frames as .jpg files in the `animated_network_bending` folder."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68775bc0",
      "metadata": {
        "id": "68775bc0"
      },
      "source": [
        "### 6.2 - Create a video using generated images as video frames  \n",
        "\n",
        "We will need [FFMPEG](https://ffmpeg.org/) to do create a video from generated frames.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4546414c",
      "metadata": {
        "id": "4546414c"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -framerate 24 -i ./{folder_name}/%05d.jpg {folder_name}.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a06be135",
      "metadata": {
        "id": "a06be135"
      },
      "source": [
        "Now the rendered video should be in the folder next to this notebook as a .mp4 file,\n",
        "We can display it here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6bca5e7",
      "metadata": {
        "id": "e6bca5e7"
      },
      "outputs": [],
      "source": [
        "mp4 = open(f'{folder_name}.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=512 controls loop>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2afff00",
      "metadata": {
        "id": "e2afff00"
      },
      "source": [
        "## **Tasks**  \n",
        "\n",
        "**(Basic)** Play with the parameters in the tutorial:\n",
        " - Changing the code for the `transformations` variable in **5.2 - Transformation Template** to customise your network bending;\n",
        " - Feel free to explore some other transformations that are not on the list, for instance, erosion and dilation, or an edge detection filter;\n",
        " - Changing latent vector $z$ by changing the random seed in step **5.3**, see if the bending effect holds for other latent vectors;\n",
        "\n",
        "**(Difficult)** We only used the human faces model in this tutorial as an example. Try to use some other pre-trained models. Take a look at these lists of pre-trained StyleGAN2 models: [Official StyleGAN2 pre-trained models](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/research/models/stylegan2/files), or this [Awesome Pretrained StyleGAN2](https://github.com/justinpinkney/awesome-pretrained-stylegan2) repository.\n",
        "\n",
        "**(More Difficult)** Try some other kinds of network bending techniques, as listed at the beginning of this tutorial. For instance, try to abuse the intermediate style vector $w$ and see if you can get some wacky results, or, corrupt the weights of a trained model as in [Mario Klingemann](https://underdestruction.com/2018/12/29/memories-of-passersby-i/).   \n",
        "Hint: You might want to check the [network_stylegan2.py](stylegan3/training/networks_stylegan2.py) file to see how the model is scripted, as well as some PyTorch's documentations on accessing a model's weights (parameters): [Module parameters in PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_parameters)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c340f65",
      "metadata": {
        "id": "8c340f65"
      },
      "source": [
        "Share your results in this Miro board:\n",
        "https://miro.com/app/board/uXjVG5VWMK4=/?share_link_id=756099302338\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6zxBO4wIyy-w",
      "metadata": {
        "id": "6zxBO4wIyy-w"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}