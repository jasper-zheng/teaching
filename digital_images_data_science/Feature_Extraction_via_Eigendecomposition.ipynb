{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasper-zheng/teaching/blob/main/digital_images_data_science/Feature_Extraction_via_Eigendecomposition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c689b093-a21d-400d-8a2b-cbcfeda9f0f6",
      "metadata": {
        "id": "c689b093-a21d-400d-8a2b-cbcfeda9f0f6"
      },
      "source": [
        "# Extracting Features from an Image Dataset via Eigendecomposition\n",
        "Materials for Methods 2: Digital Systems, Week 4: **Digital Images x Data Science**.    \n",
        "Author: Jasper Shuoyang Zheng  \n",
        "\n",
        "\n",
        "In this notebook, we'll do a **Principle Component Analysis (PCA)** on a dataset of animal faces to discover eigenfaces (\"typical-faces\"/ \"characteristic-faces\") in a animal face images dataset.  \n",
        "\n",
        "PCA is a very common statistical procedure that transforms a large set of variables into smaller ones but preserving the most common information in the large set.\n",
        "\n",
        "**Dataset:** We'll use a very small subset of the [Animal Faces High Quality (AFHQ)](https://github.com/clovaai/stargan-v2) Dataset as our face images dataset. The original AFHQ is an open-source dataset that has over 200k images of human faces."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b26f08ab-1c53-4960-8347-5eb9d0dfda0e",
      "metadata": {
        "id": "b26f08ab-1c53-4960-8347-5eb9d0dfda0e"
      },
      "source": [
        "## Preparation: Unzip the image folder\n",
        "\n",
        "I have prepared the AFHQ subset in the `animal_faces_1000.zip` file, we can use the following code to unzip it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14be99d6-ab55-4551-ab10-6510f8f62d95",
      "metadata": {
        "id": "14be99d6-ab55-4551-ab10-6510f8f62d95"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os, os.path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset\n",
        "!wget https://github.com/jasper-zheng/teaching/blob/main/digital_images_data_science/animal_faces_1000.zip?raw=true -O animal_faces_1000.zip"
      ],
      "metadata": {
        "id": "ij0UsUQwgPB7"
      },
      "id": "ij0UsUQwgPB7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42f009b0-6145-4a14-a49d-87e884f15e5b",
      "metadata": {
        "id": "42f009b0-6145-4a14-a49d-87e884f15e5b"
      },
      "outputs": [],
      "source": [
        "folder_path='animal_faces_1000.zip'\n",
        "import zipfile\n",
        "\n",
        "def unzip_folder(zip_path, destination_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(destination_path)\n",
        "\n",
        "unzip_folder(folder_path, '')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b4eb680-45b7-4e3f-a685-8ade91b3e6dd",
      "metadata": {
        "id": "4b4eb680-45b7-4e3f-a685-8ade91b3e6dd"
      },
      "source": [
        "## **Step 1:** Load all image files into a tensor\n",
        "\n",
        "After unzipping, if you refresh the file browser, you'll see the unzipped folder `animal_faces_1000`, inside it should contain 1000 face images in `.jpg` format.\n",
        "\n",
        "Now we'll need to load all these images into stack of image matrices: We learned how to load one image into a matrix last week, we can write a for-loop to iterate through all images in the folder and load them one-by-one.  \n",
        "\n",
        "The following code will help us to do this, it loads all images in the folder, resize, [crop](https://www.geeksforgeeks.org/python-pil-image-crop-method/), and convert them into greyscale mode, and  into a `NumPy` array. Read through the code and try to understand the code as much as you can (feel free to ask ChatGPT to explain certain lines for you)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc7c6ede-bc30-49e7-a765-9b7fd913f5ba",
      "metadata": {
        "id": "bc7c6ede-bc30-49e7-a765-9b7fd913f5ba"
      },
      "outputs": [],
      "source": [
        "# create an empty list of images\n",
        "imgs = []\n",
        "\n",
        "path = \"./animal_faces_1000\"\n",
        "path = os.path.join(path,'')\n",
        "\n",
        "size_x = 100\n",
        "size_y = 120\n",
        "crop_boundaries = (15, 15, 85, 105)\n",
        "\n",
        "# supported file extension:\n",
        "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
        "\n",
        "for i,f in enumerate(os.listdir(path)):\n",
        "\n",
        "    # split the full filename (include the extension) to filename and its extension\n",
        "    ext = os.path.splitext(f)[1]\n",
        "    filename = os.path.splitext(f)[0]\n",
        "\n",
        "    # if the file extension is not in the supported extension list, then skip it\n",
        "    if ext.lower() not in valid_images:\n",
        "        continue\n",
        "\n",
        "    # open a image, resize it, convert it to greyscale ('L' refers to lightness), and then crop it\n",
        "    img = Image.open(os.path.join(path,f)).resize((size_x,size_y)).convert('L').crop(crop_boundaries)\n",
        "\n",
        "    # add the opened image to our list of image\n",
        "    imgs.append(img)\n",
        "\n",
        "    if i%100==0:\n",
        "        print(f'processed {i} images')\n",
        "\n",
        "img_data = np.array(imgs)\n",
        "\n",
        "print(f'loaded into tensor: {img_data.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "629f0723-b0cc-45c5-b5cc-fdfb14b5b87a",
      "metadata": {
        "id": "629f0723-b0cc-45c5-b5cc-fdfb14b5b87a"
      },
      "source": [
        "Now we have the `img_data` variable, which is a tensor shaped (1000, 90, 70), 1000 indicates we have 1000 images, 90 indicates their height, 70 indicates their width.  \n",
        "\n",
        "Let's display some examples in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3d3812d-acc5-4f1d-a7ba-6c31f0a32926",
      "metadata": {
        "id": "e3d3812d-acc5-4f1d-a7ba-6c31f0a32926"
      },
      "outputs": [],
      "source": [
        "# Set up the 4x2 grid for subplots\n",
        "fig, axes = plt.subplots(2, 4, figsize=(6, 4))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(img_data[i], cmap='grey')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e451ff6-5c64-4ce1-b3e9-e5c3faa25740",
      "metadata": {
        "id": "7e451ff6-5c64-4ce1-b3e9-e5c3faa25740"
      },
      "source": [
        "## **Step 2:** Normalisation  \n",
        "\n",
        "Normalisation is a technique to scale the tensor into a specific range. Now we have the image tensor with a range of 0 to 255, in data science, a common practice is to normalise all data between the range of 0 to 1.0 (as float numbers).\n",
        "\n",
        "To do this, first, we can apply a scalar $1/255$ to our tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b49b5d3f-0587-4b6b-888a-ea4c32120296",
      "metadata": {
        "id": "b49b5d3f-0587-4b6b-888a-ea4c32120296"
      },
      "outputs": [],
      "source": [
        "print(f'maximum number in the tensor: {img_data.max()}, \\nminimum number in the tensor: {img_data.min()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddbfce3a-1145-405a-89de-077151829486",
      "metadata": {
        "id": "ddbfce3a-1145-405a-89de-077151829486"
      },
      "outputs": [],
      "source": [
        "img_data = img_data * 1/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63f414db-bd44-47a4-836d-cbcefa80e446",
      "metadata": {
        "id": "63f414db-bd44-47a4-836d-cbcefa80e446"
      },
      "outputs": [],
      "source": [
        "print('after normalisation:')\n",
        "print(f'maximum number in the tensor: {img_data.max()}, \\nminimum number in the tensor: {img_data.min()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81488d47-ac24-4157-b999-866dbdb0834a",
      "metadata": {
        "id": "81488d47-ac24-4157-b999-866dbdb0834a"
      },
      "source": [
        "## **Step 3:** Subtract the mean face  \n",
        "\n",
        "In addition, we also need to subtract a mean face from the whole dataset. The mean face is the average value of each pixel calculated from the whole dataset, by subtracting it from the entire tensor, it tells us how different each face is.\n",
        "\n",
        "Let's start by calculating the mean face.  \n",
        "In the following line, it uses NumPy's built-in mean function to calculate the average value across the first (0) axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20bd7029-1cb3-4e43-8f0f-9ec794645219",
      "metadata": {
        "id": "20bd7029-1cb3-4e43-8f0f-9ec794645219"
      },
      "outputs": [],
      "source": [
        "mean_face = img_data.mean(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00c64d13-87ce-4810-8114-6de01da96874",
      "metadata": {
        "id": "00c64d13-87ce-4810-8114-6de01da96874"
      },
      "source": [
        "The resulting tensor should have a shape of `(90, 70)` because the first axis has been averaged. Now we can plot the mean face tensor as an image, using the MatplotLib library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0803746-bb36-4161-b415-3943833bca8b",
      "metadata": {
        "id": "e0803746-bb36-4161-b415-3943833bca8b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(3,3))\n",
        "# the 'cmap' parameter define thecolour scheme of the visualisation\n",
        "plt.imshow(mean_face, cmap='gray')\n",
        "# hide the axis\n",
        "plt.axis(True)\n",
        "# display the graph\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6319a5ce-266e-4a7b-a295-3077d692f50c",
      "metadata": {
        "id": "6319a5ce-266e-4a7b-a295-3077d692f50c"
      },
      "source": [
        "Now we subtract this mean face from the entire face tensor to get the difference between each image and the mean, we call this the \"difference tensor\".  \n",
        "\n",
        "> **Note:** Mathematically, we can only subtract tensors that have the same shape, but in the following line of code we are subtracting the `img_data` shaped (1000, 90, 70) by `mean_face` shaped (90, 70). This works fine because Python has automatically broadcasted the mean_face from (90, 70) to (1000, 90, 70). More about tensor broadcasting: [here](https://www.geeksforgeeks.org/tensor-broadcasting/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65f97b37-62b9-4237-a9a4-70a8a7e7af15",
      "metadata": {
        "id": "65f97b37-62b9-4237-a9a4-70a8a7e7af15"
      },
      "outputs": [],
      "source": [
        "img_data = img_data - mean_face"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7ebee8f-baef-49e4-8bc3-5c2a7bfffa6b",
      "metadata": {
        "id": "f7ebee8f-baef-49e4-8bc3-5c2a7bfffa6b"
      },
      "source": [
        "## **Step 4:** Flatten each image into a vector  \n",
        "\n",
        "In order to do matrix decomposition, we need to flatten our difference tensor into a matrix. Our difference tensor is currently a 3-dimensional tensor, we can flatten the width and height dimensions of it, so that we'll get a very large matrix, which has its **column repesenting the number of images**, and **row representing each pixel value**. The structure of our new difference matrix $B$ looks like this:\n",
        "\n",
        "$B = \\begin{bmatrix}\n",
        "i&i&...&i\\\\\n",
        "m&m&...&m\\\\\n",
        "a&a&...&a\\\\\n",
        "g&g&...&g\\\\\n",
        "e&e&...&e\\\\\n",
        "1&2&...&n\n",
        "\\end{bmatrix}$  \n",
        " .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12156f54-b0bb-4703-9188-465fd1c29462",
      "metadata": {
        "id": "12156f54-b0bb-4703-9188-465fd1c29462"
      },
      "outputs": [],
      "source": [
        "print(f'shape before flatten: {img_data.shape}')\n",
        "img_data_flatten = img_data.reshape(img_data.shape[0],img_data.shape[1]*img_data.shape[2]).T\n",
        "print(f'shape after flatten: {img_data_flatten.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe74aa58-f54f-4ad8-8bc9-98035989e236",
      "metadata": {
        "id": "fe74aa58-f54f-4ad8-8bc9-98035989e236"
      },
      "source": [
        "Now we can see the shape of the flatten tensor is `(6300,1000)`, we have 6300 because this is the number of pixels in one image ($90\\times70=6300$)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6002dce0-d9a2-433b-886b-dcec4ac79858",
      "metadata": {
        "id": "6002dce0-d9a2-433b-886b-dcec4ac79858"
      },
      "source": [
        "## **Step 5:** Create a correlation matrix  \n",
        "\n",
        "Before decomposing our data matrix, we're going to do an extra step, that is to turn our data matrix to a correlation matrix. A correlation matrix $C$ is the result of the dot product between **transposed difference matrix** and the **difference matrix itself**, i.e.:  \n",
        "\n",
        "$C=B^TB=\\begin{bmatrix}\n",
        "image 1\\\\\n",
        "image 2\\\\\n",
        "...\\\\\n",
        "image n\n",
        "\\end{bmatrix} \\times \\begin{bmatrix}\n",
        "i&i&...&i\\\\\n",
        "m&m&...&m\\\\\n",
        "a&a&...&a\\\\\n",
        "g&g&...&g\\\\\n",
        "e&e&...&e\\\\\n",
        "1&2&...&n\n",
        "\\end{bmatrix}\n",
        "$, resulting in shape `(1000,1000)`\n",
        "\n",
        "And we also have the full correlation matrix $C^\\prime$ which is the dot product between the **difference matrix** and the **transposed difference matrix**, i.e.:\n",
        "\n",
        "$C^\\prime=BB^T=\\begin{bmatrix}\n",
        "i&i&...&i\\\\\n",
        "m&m&...&m\\\\\n",
        "a&a&...&a\\\\\n",
        "g&g&...&g\\\\\n",
        "e&e&...&e\\\\\n",
        "1&2&...&n\n",
        "\\end{bmatrix}\\times\\begin{bmatrix}\n",
        "image 1\\\\\n",
        "image 2\\\\\n",
        "...\\\\\n",
        "image n\n",
        "\\end{bmatrix}\n",
        "$, resulting in shape `(6300,6300)`.  \n",
        "\n",
        "$C$ seems much easier to solve, so we start by working with $C$ and later tranform the results to $C^\\prime$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be92a87c-a53e-4db4-ad5a-f2fa524ff52c",
      "metadata": {
        "id": "be92a87c-a53e-4db4-ad5a-f2fa524ff52c"
      },
      "outputs": [],
      "source": [
        "C = img_data_flatten.T.dot(img_data_flatten)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48ba7c56-08aa-417c-abc4-3c303ef4345f",
      "metadata": {
        "id": "48ba7c56-08aa-417c-abc4-3c303ef4345f"
      },
      "source": [
        "If you remember how do we calculate maxtrix $\\times$ matrix multiplication (dot product), the above operation should give us a resulting matrix of size `(1000, 1000)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb6fe7c3-24a4-4890-bdbf-529419ae78a8",
      "metadata": {
        "id": "cb6fe7c3-24a4-4890-bdbf-529419ae78a8"
      },
      "outputs": [],
      "source": [
        "print(C.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd0e7f79-9b7f-4273-aed0-f52e71fe9bcd",
      "metadata": {
        "id": "cd0e7f79-9b7f-4273-aed0-f52e71fe9bcd"
      },
      "source": [
        "## **Step 6:** Calculate eigenvalues and eigenvectors  \n",
        "\n",
        "### Eigenvalues and eigenvectors for correlation matrix $C$  \n",
        "Now we calculate the eigenvalues $\\lambda_i$ and eigenvectors $v_i$ for our correlation matrix $C$, that is, to solve all three variables in $Cv_i=\\lambda_iv_i$. We can use `NumPy`'s [`eig()` funciton](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html) to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ead0df58-0522-461d-9de8-2b6dd73ddce5",
      "metadata": {
        "id": "ead0df58-0522-461d-9de8-2b6dd73ddce5"
      },
      "outputs": [],
      "source": [
        "from numpy.linalg import eig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c64014f-6257-4b38-978a-3e00bd8cdb64",
      "metadata": {
        "id": "6c64014f-6257-4b38-978a-3e00bd8cdb64"
      },
      "outputs": [],
      "source": [
        "eigenvalues, eigenvectors = eig(C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fb1d7bd-cfe6-476d-b60d-a1face90eb23",
      "metadata": {
        "id": "1fb1d7bd-cfe6-476d-b60d-a1face90eb23"
      },
      "outputs": [],
      "source": [
        "print(f'eigenvalues shape: {eigenvalues.shape}')\n",
        "print(f'eigenvectors shape: {eigenvectors.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b76ca8f-5d26-4648-9609-0d5483ee646b",
      "metadata": {
        "id": "0b76ca8f-5d26-4648-9609-0d5483ee646b"
      },
      "source": [
        "### Eigenvectors for full correlation matrix $C^\\prime$  \n",
        "\n",
        "In the lecture, we mentioned that we can derive the eigenvectors $u_i$ for the full correlation matrix $C^\\prime$ by formula $u_i=Bv_i$, in which $B$ is the difference matrix, $v_i$ is the eigenvectors for correlation matrix $C$.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3cae643-8385-46c8-9ea7-b5d8a34da07a",
      "metadata": {
        "id": "c3cae643-8385-46c8-9ea7-b5d8a34da07a"
      },
      "outputs": [],
      "source": [
        "eigenvectors_full = img_data_flatten.dot(eigenvectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "618e93d9-a36f-4d6f-b678-39049de5f2ad",
      "metadata": {
        "id": "618e93d9-a36f-4d6f-b678-39049de5f2ad"
      },
      "source": [
        "This will give us 1000 eigenvectors $u_i$, each has 6300 numbers, corresponding to each pixel value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97baf4ca-c322-4582-b561-00dd472b47c8",
      "metadata": {
        "id": "97baf4ca-c322-4582-b561-00dd472b47c8"
      },
      "outputs": [],
      "source": [
        "print(f'ui shape: {eigenvectors_full.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45f810dc-3743-423c-be89-0dba8ff04659",
      "metadata": {
        "id": "45f810dc-3743-423c-be89-0dba8ff04659"
      },
      "source": [
        "## **Step 7:** Sort eigenvectors based on their eigenvalues\n",
        "\n",
        "The eigenvectors corresponding to the highest eigenvalues provide the most common information about our dataset. Therefore, we can sort our eigenvectors $u_i$ based on the magnitude of their eigenvalues $\\lambda_i$. We can use `NumPy`'s argsort function to get the sorted indexes of $\\lambda_i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c4b655-402a-4188-a71d-1b1a493bf141",
      "metadata": {
        "id": "d0c4b655-402a-4188-a71d-1b1a493bf141"
      },
      "outputs": [],
      "source": [
        "sorted_index = np.argsort(eigenvalues)[::-1]\n",
        "eigenvals_sorted = eigenvalues[sorted_index]\n",
        "eigenvecs_sorted = eigenvectors_full[:,sorted_index]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7bcf351-65ae-4683-88d9-83b2aeed1b74",
      "metadata": {
        "id": "b7bcf351-65ae-4683-88d9-83b2aeed1b74"
      },
      "source": [
        "Now we can cumulative sum of the eigenvalues to see how many eigenvectors capture the most information in the dataset (the image tensor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681db4c3-f761-4e1d-88df-67f9e9896357",
      "metadata": {
        "id": "681db4c3-f761-4e1d-88df-67f9e9896357"
      },
      "outputs": [],
      "source": [
        "cumulative_eigenvals = np.cumsum(eigenvals_sorted)\n",
        "\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(cumulative_eigenvals)\n",
        "plt.title('how many eigenvectors capture most information in the image tensor?')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "608f5f25-f6b4-4fb2-b463-33fb2d503c62",
      "metadata": {
        "id": "608f5f25-f6b4-4fb2-b463-33fb2d503c62"
      },
      "source": [
        "If we look at the plot above, we see that majority of the information is captured by roughly the first 50~100 features.\n",
        "\n",
        "> Note: Now we got the estimation of 50~100 purely based on our observation from the plot, this fine but not the best way to do it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a526884-16c4-48c6-8d7b-bf642ab2af2c",
      "metadata": {
        "id": "4a526884-16c4-48c6-8d7b-bf642ab2af2c"
      },
      "source": [
        "## **Step 8:** Plot some eigenfaces  \n",
        "\n",
        "We have got the sorted version of eigenvectors $u_i$, and let's only preserve the first 50 vectors because they have captured most information about our dataset.\n",
        "\n",
        "Besides, they are now in a flatten structure (50, 6300). So now we need to reshape this flatten eigenvectors to a image tensor, they will be our **eigenfaces**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7282c02-19bb-4227-8282-58b62518297f",
      "metadata": {
        "id": "e7282c02-19bb-4227-8282-58b62518297f"
      },
      "outputs": [],
      "source": [
        "eigenvecs_sorted = eigenvecs_sorted[:,:50]\n",
        "eigenfaces = eigenvecs_sorted.reshape((img_data.shape[1],img_data.shape[2],50))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e22bcaa-82c7-4d70-9e0c-dfb81aadf64c",
      "metadata": {
        "id": "6e22bcaa-82c7-4d70-9e0c-dfb81aadf64c"
      },
      "source": [
        "Now we can plot the first 50 eigenfaces to see what are the most important features in our face dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0deaef3b-5311-41ef-9c17-54db377e1ee9",
      "metadata": {
        "id": "0deaef3b-5311-41ef-9c17-54db377e1ee9"
      },
      "outputs": [],
      "source": [
        "# Set up the 5x10 grid for subplots\n",
        "fig, axes = plt.subplots(5, 10, figsize=(10, 6))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(eigenfaces[:,:,i], cmap='grey')\n",
        "    ax.set_axis_off()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aae4cc9-3f89-414c-87ae-87528c21954e",
      "metadata": {
        "id": "7aae4cc9-3f89-414c-87ae-87528c21954e"
      },
      "source": [
        "**Interpretation of the results:** The first two eigenfaces present the most dominant feature of the dataset, which is the round shape of the face. From the third and the fourth eigenfaces, we can start to see the position of the eyes. Starting from the fifth eigenface, we can see the hair and face separation, and the facial elements, such as the nose and the mouth, become clearer. The seventh eigenface has an emphasis on the eye sockets. Starting from the second row, we can distinguish some facial expressions, such as smiling and neutral faces."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be2a6eba-b955-49fd-9bae-aac51e176e7b",
      "metadata": {
        "id": "be2a6eba-b955-49fd-9bae-aac51e176e7b"
      },
      "source": [
        "## Extracting new faces  \n",
        "\n",
        "Now we can use our eigenvectors to analyse new faces, we call this process \"exrtracting features from new data\".  \n",
        "\n",
        "#### Load new faces\n",
        "Let's first randomly pick three faces image from the dataset and load them into tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90fa5ba5-6180-4651-993b-442453f337aa",
      "metadata": {
        "id": "90fa5ba5-6180-4651-993b-442453f337aa"
      },
      "outputs": [],
      "source": [
        "new_img_1 = Image.open('./animal_faces_1000/cat_00000.jpg').resize((size_x,size_y)).convert('L').crop(crop_boundaries)\n",
        "new_img_2 = Image.open('./animal_faces_1000/cat_00123.jpg').resize((size_x,size_y)).convert('L').crop(crop_boundaries)\n",
        "new_img_3 = Image.open('./animal_faces_1000/dog_00155.jpg').resize((size_x,size_y)).convert('L').crop(crop_boundaries)\n",
        "new_imgs = np.array([new_img_1,new_img_2,new_img_3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f4d8b9-1073-4338-9d38-d5a63cdae9fb",
      "metadata": {
        "id": "06f4d8b9-1073-4338-9d38-d5a63cdae9fb"
      },
      "outputs": [],
      "source": [
        "# Set up the 5x10 grid for subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(6, 3))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(new_imgs[i], cmap='grey')\n",
        "    ax.set_axis_off()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf19a38a-cb31-44e9-aa3b-a91d5f31a8b0",
      "metadata": {
        "id": "cf19a38a-cb31-44e9-aa3b-a91d5f31a8b0"
      },
      "source": [
        "We're going to do the same things as before, that is to first normalise them, then substract the mean face from them, and then flatten to a matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f799b701-c82e-482a-915e-a3341dc3055f",
      "metadata": {
        "id": "f799b701-c82e-482a-915e-a3341dc3055f"
      },
      "outputs": [],
      "source": [
        "new_imgs_diff = 1/255.*new_imgs - mean_face\n",
        "new_difference_matrix = new_imgs_diff.reshape(new_imgs_diff.shape[0],-1).T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31e071d1-9b95-4b95-98c9-00f5d4996494",
      "metadata": {
        "id": "31e071d1-9b95-4b95-98c9-00f5d4996494"
      },
      "source": [
        "#### Projection into eigen space\n",
        "\n",
        "Now we can project our new faces into the eigen space to calculate their eigen coefficients. We can do this by taking the dot product between the eigenvectors and the new faces' difference matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0792c6f-5c3c-474c-b514-f380488bc546",
      "metadata": {
        "id": "f0792c6f-5c3c-474c-b514-f380488bc546"
      },
      "outputs": [],
      "source": [
        "eigen_coefficients = eigenvecs_sorted.T.dot(new_difference_matrix).T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb126525-da8a-4a83-a4bf-8a4ba5210577",
      "metadata": {
        "id": "fb126525-da8a-4a83-a4bf-8a4ba5210577"
      },
      "source": [
        "#### Plot the eigen coefficients of new faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97310eb5-51fe-4147-8a98-2fc28c703f76",
      "metadata": {
        "id": "97310eb5-51fe-4147-8a98-2fc28c703f76"
      },
      "outputs": [],
      "source": [
        "# Set up the 5x10 grid for subplots\n",
        "fig, axes = plt.subplots(3, 2, figsize=(6, 5))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i%2==0:\n",
        "        ax.imshow(new_imgs[i//2], cmap='grey')\n",
        "    else:\n",
        "        ax.bar(np.arange(0,50),eigen_coefficients[i//2])\n",
        "    ax.set_axis_off()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05501952-7b60-4791-9835-8e964e95da42",
      "metadata": {
        "id": "05501952-7b60-4791-9835-8e964e95da42"
      },
      "source": [
        "#### Comparing coefficients by $L^2$ distance  \n",
        "\n",
        "In week 2 we mentioned comparing two vectors by $L^2$ (Euclidean) distance, now we can use it to compare the different between these three eigen coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c14a823d-ec1a-4718-8b6b-d3520ab95c1a",
      "metadata": {
        "id": "c14a823d-ec1a-4718-8b6b-d3520ab95c1a"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d2cb3fb-16b2-4892-90b5-2a1c1dd4357d",
      "metadata": {
        "id": "0d2cb3fb-16b2-4892-90b5-2a1c1dd4357d"
      },
      "outputs": [],
      "source": [
        "distance_0_1 = math.dist(eigen_coefficients[0], eigen_coefficients[1])\n",
        "distance_0_2 = math.dist(eigen_coefficients[0], eigen_coefficients[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35cf714c-8f60-44c4-898c-ec3ec20acd4e",
      "metadata": {
        "id": "35cf714c-8f60-44c4-898c-ec3ec20acd4e"
      },
      "outputs": [],
      "source": [
        "print(f'the distance between the 1 and 2 faces is {distance_0_1}')\n",
        "print(f'the distance between the 1 and 3 faces is {distance_0_2}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}